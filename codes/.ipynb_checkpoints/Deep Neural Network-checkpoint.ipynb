{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network (DNN)\n",
    "\n",
    "\n",
    "![dnn](http://ufldl.stanford.edu/tutorial/images/Network3322.png)\n",
    "\n",
    "\n",
    "* **neuron** is a unit that takes input vector and outputs a single value.\n",
    "* **layer** is a set of neurons with the same input vector.\n",
    "* **NN** is a set of layers that are serially connected.\n",
    "\n",
    "## Neuron\n",
    "![neuron](https://www.dropbox.com/s/b6juegvqmaul9zm/Neuron.png?dl=0&raw=1)\n",
    "* A neuron defines a hyperplane and computes the distance from the hyperplane\n",
    "* The distance is non-linearly transformed.\n",
    "\n",
    "## Layer\n",
    "* just a **linear (affine) map + coordinate-wise non-linear transform**\n",
    "![nonlinear](https://upload.wikimedia.org/wikipedia/en/thumb/9/96/Jacobian_determinant_and_distortion.svg/1280px-Jacobian_determinant_and_distortion.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Implementation\n",
    "\n",
    "Now let's implement NN in `tensorflow`!\n",
    "\n",
    "### Layer\n",
    "$$ h = \\sigma (xw + b)$$\n",
    "where\n",
    "$ x \\in \\mathbb{R}^{n \\times d}$,\n",
    "$ w \\in \\mathbb{R}^{d \\times h}$,\n",
    "$ b \\in \\mathbb{R}^{h}$,\n",
    "$ h \\in \\mathbb{R}^{n \\times h}$ \n",
    "and $\\sigma(\\cdot)$ is a non-linear activation function.\n",
    "\n",
    "Let us define the tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder('float32', name='x')\n",
    "\n",
    "initial_w = tf.truncated_normal(\n",
    "                shape=(784, 50),\n",
    "                mean=0.0, stddev=0.05 )\n",
    "w = tf.Variable(initial_w, name='w')\n",
    "b = tf.Variable(tf.zeros(shape=(50,)), name='b')\n",
    "\n",
    "p = tf.matmul(x, w) + b\n",
    "h = tf.sigmoid(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"x:0\", dtype=float32)\n",
      "<tensorflow.python.ops.variables.Variable object at 0x7f08fa1dbf90>\n",
      "<tensorflow.python.ops.variables.Variable object at 0x7f08fa1dbf50>\n",
      "Tensor(\"add:0\", shape=(?, 50), dtype=float32)\n",
      "Tensor(\"Sigmoid:0\", shape=(?, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print x\n",
    "print w\n",
    "print b\n",
    "print p\n",
    "print h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: \n",
      "[[ 0.01170039  0.03081924 -0.03341355 ..., -0.05013648  0.06999285\n",
      "  -0.02501209]\n",
      " [ 0.09782187 -0.05770919  0.05078177 ...,  0.04800818 -0.02364256\n",
      "   0.04929907]\n",
      " [-0.0192522  -0.0016696  -0.00286393 ...,  0.03492413  0.00486213\n",
      "   0.02429403]\n",
      " ..., \n",
      " [ 0.04579539  0.07084817  0.02263879 ..., -0.03819674 -0.01520984\n",
      "   0.00336086]\n",
      " [ 0.03129913  0.00667761 -0.00481091 ..., -0.0376614   0.09721918\n",
      "   0.03021369]\n",
      " [ 0.06360533  0.04421287  0.04556337 ...,  0.03088005  0.01524972\n",
      "   0.00981149]]\n",
      "b: \n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "p shape: \n",
      "[10 50]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sess.close()\n",
    "except NameError:\n",
    "    pass\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "# Load values on GPU\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init) \n",
    "\n",
    "print \"w: \\n\", sess.run(w)\n",
    "print \"b: \\n\", sess.run(b)\n",
    "# print sess.run(p)  # Error. Cause we did not fed the `x`\n",
    "print \"p shape: \\n\", sess.run(tf.shape(p), feed_dict={x: np.zeros(shape=(10,784))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set of Layers\n",
    "To stack the layers, let us generalize a little bit the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of layers:  3\n"
     ]
    }
   ],
   "source": [
    "layer_spec = [784, 100, 30, 10]\n",
    "n_layer = len(layer_spec)-1\n",
    "print \"num of layers: \", n_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the final layer of NN is logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, name='x')\n",
    "\n",
    "inp = x\n",
    "hs = []\n",
    "for l in xrange(n_layer):\n",
    "    with tf.name_scope('p{}'.format(l)):\n",
    "\n",
    "        initial_w = tf.truncated_normal(\n",
    "                shape=(layer_spec[l], layer_spec[l+1]),\n",
    "                mean=0.0, stddev=0.05)\n",
    "        w = tf.Variable(initial_w, name='w')\n",
    "        b = tf.Variable(tf.zeros((layer_spec[l+1],)), name='b')\n",
    "        p = tf.matmul(inp,w) + b\n",
    "\n",
    "    with tf.name_scope('h{}'.format(l)):\n",
    "\n",
    "        if l == n_layer-1: # Last layer\n",
    "            h = p\n",
    "        else: \n",
    "            h = tf.nn.relu(p)\n",
    "        hs.append(h)\n",
    "        inp = h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h shape: \n",
      "[30 10]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sess.close()\n",
    "except NameError:\n",
    "    pass\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "# Load values on GPU\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init) \n",
    "\n",
    "print \"h shape: \\n\", sess.run(tf.shape(hs[-1]), feed_dict={x: np.zeros(shape=(30,784))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss\n",
    "We define the loss as the **negative log-likelihood**, or the **cross-entropy**.\n",
    "$$\\sum_i \\sum_k -\\mathcal{I}(t_i=k) \\log P(y_i=k|x_i;\\theta)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = tf.placeholder('int32', name='t')\n",
    "xent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            hs[-1], t, name='xent')\n",
    "\n",
    "loss = tf.reduce_mean(xent, name='loss')\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "\n",
    "#pred = tf.argmax(hs[-1], axis=1)\n",
    "pred = tf.reduce_max(hs[-1], reduction_indices=[1])\n",
    "\n",
    "\n",
    "correct = tf.nn.in_top_k(hs[-1], t, 1)\n",
    "acc = tf.reduce_mean(tf.cast(correct, tf.float32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "We use MNIST hand-written digit recognition data.\n",
    "* Total 70k images\n",
    "* 784 dimension (28x28 pixels, gray-scale) \n",
    "* Train, Test, Validation Sets are divided a priori.\n",
    "\n",
    "The objective is to classify each image as one of 10 classes (0-9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'test_t', u'test_x', u'train_t', u'train_x', u'valid_t', u'valid_x']\n",
      "(55000, 784)\n",
      "class:  7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD8CAYAAABTq8lnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzeMevz0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f08f9f87d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h5py\n",
    "mnist = h5py.File('../mnist.hdf5','r')\n",
    "print mnist.keys()\n",
    "print mnist['train_x'].shape\n",
    "\n",
    "train_x = mnist['train_x'][()]\n",
    "train_t = mnist['train_t'][()]\n",
    "\n",
    "plt.imshow(train_x[0].reshape((28, 28)), \n",
    "               interpolation='nearest', cmap=plt.get_cmap('gray'))\n",
    "print \"class: \", train_t[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent\n",
    "Loss:\n",
    "$$ \\mathcal{L}(X; \\theta) = \\frac{1}{n} \\sum_{i=1}^n \\mathcal{L(x_i; \\theta)}$$\n",
    "Gradient Descent:\n",
    "$$ \\theta^{t+1} = \\theta^{t} - \\eta \\frac{1}{n}\\sum_{i=1}^n \\frac{\\partial \\mathcal{L}(X_i;\\theta)}{\\partial \\theta} \\vert _{\\theta=\\theta^t} $$\n",
    "\n",
    "Stochastic Gradient Descent:\n",
    "\n",
    "---\n",
    "**for** $k=1$ **to** $n/m$:\n",
    "$$ \\theta^{k+1} = \\theta^{k} - \\eta \\frac{1}{k}\\sum_{i=1}^m \\frac{\\partial \\mathcal{L}(X_i;\\theta)}{\\partial \\theta} \\vert _{\\theta=\\theta^k} $$\n",
    "**end**\n",
    "\n",
    "$\\theta^{t+1}=\\theta^{k=n/m}$\n",
    "\n",
    "---\n",
    "**Principle**:\n",
    "\n",
    "*Instead of computing the exact gradient direction using the full batch data and update once, compute a **noisy gradient** direction using partial (mini-batch) data and update **multiple times**.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 2.29871177673, Acc: 0.173999994993\n",
      "Epoch: 1, Loss: 2.27780485153, Acc: 0.306909114122\n",
      "Epoch: 2, Loss: 2.21257591248, Acc: 0.360654532909\n",
      "Epoch: 3, Loss: 1.96100187302, Acc: 0.43969091773\n",
      "Epoch: 4, Loss: 1.49118208885, Acc: 0.592581868172\n",
      "Epoch: 5, Loss: 1.06805336475, Acc: 0.694236397743\n",
      "Epoch: 6, Loss: 0.800314426422, Acc: 0.770963609219\n",
      "Epoch: 7, Loss: 0.647313117981, Acc: 0.8166000247\n",
      "Epoch: 8, Loss: 0.563945233822, Acc: 0.8405636549\n",
      "Epoch: 9, Loss: 0.512508392334, Acc: 0.855327248573\n",
      "Epoch: 10, Loss: 0.476745158434, Acc: 0.865672707558\n",
      "Epoch: 11, Loss: 0.449486494064, Acc: 0.872727274895\n",
      "Epoch: 12, Loss: 0.427356809378, Acc: 0.878509104252\n",
      "Epoch: 13, Loss: 0.408805549145, Acc: 0.884290874004\n",
      "Epoch: 14, Loss: 0.392937600613, Acc: 0.888327300549\n",
      "Epoch: 15, Loss: 0.379130154848, Acc: 0.892618179321\n",
      "Epoch: 16, Loss: 0.366949230433, Acc: 0.895709037781\n",
      "Epoch: 17, Loss: 0.356020629406, Acc: 0.899272739887\n",
      "Epoch: 18, Loss: 0.346040070057, Acc: 0.902090907097\n",
      "Epoch: 19, Loss: 0.336832106113, Acc: 0.904509067535\n",
      "Epoch: 20, Loss: 0.328290909529, Acc: 0.906799972057\n",
      "Epoch: 21, Loss: 0.320320725441, Acc: 0.909581840038\n",
      "Epoch: 22, Loss: 0.312829434872, Acc: 0.911454558372\n",
      "Epoch: 23, Loss: 0.305770158768, Acc: 0.913399994373\n",
      "Epoch: 24, Loss: 0.299078583717, Acc: 0.915927290916\n",
      "Epoch: 25, Loss: 0.292691528797, Acc: 0.917709052563\n",
      "Epoch: 26, Loss: 0.286574691534, Acc: 0.919418156147\n",
      "Epoch: 27, Loss: 0.280699849129, Acc: 0.920909106731\n",
      "Epoch: 28, Loss: 0.275077134371, Acc: 0.92221814394\n",
      "Epoch: 29, Loss: 0.269695222378, Acc: 0.923745453358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f08f801db10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEPCAYAAABCyrPIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIIiICKBAEBGRiAJBREQA+H8h7siaqaAC/gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f09304bd950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "num_train = train_x.shape[0]\n",
    "mb_size = 200\n",
    "num_mbs = int(num_train / mb_size)\n",
    "\n",
    "loss_history = []\n",
    "for epoch in xrange(30):\n",
    "    loss_vals = []\n",
    "    acc_vals = []\n",
    "    for mb in xrange(num_mbs):\n",
    "        data_x = train_x[mb*mb_size : (mb+1)*mb_size] \n",
    "        data_t = train_t[mb*mb_size : (mb+1)*mb_size] \n",
    "\n",
    "        _, loss_val, acc_val = sess.run([train_step, loss, acc], \n",
    "                                            feed_dict={x: data_x, t: data_t})\n",
    "        loss_vals.append(loss_val)\n",
    "        acc_vals.append(acc_val)\n",
    "        \n",
    "    print \"Epoch: {}, Loss: {}, Acc: {}\".format(\n",
    "        epoch, np.mean(loss_vals), np.mean(acc_vals) )\n",
    "\n",
    "    loss_history.append(np.mean(loss_vals))\n",
    "\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc:  0.9274\n"
     ]
    }
   ],
   "source": [
    "test_x = mnist['test_x']\n",
    "test_t = mnist['test_t']\n",
    "test_mb_size = 200\n",
    "test_num_mbs = test_x.shape[0] / test_mb_size\n",
    "\n",
    "test_accs = []\n",
    "for mb in xrange(test_num_mbs):\n",
    "    test_acc = sess.run(acc, feed_dict={\n",
    "        x: test_x[mb*test_mb_size : (mb+1)*test_mb_size],\n",
    "        t: test_t[mb*test_mb_size : (mb+1)*test_mb_size]})\n",
    "    test_accs.append(test_acc)\n",
    "print \"test acc: \", np.mean(test_accs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
